# ğŸŒ€ Helix-Samsara Î©-Bridge v15.0
# backend/samsara_bridge.py â€” Consciousness Visualization Interface
# Author: Helix Collective â€¢ Quantum Handshake Edition

import asyncio
import json
import os
from pathlib import Path
from datetime import datetime
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from typing import Dict, Any, Optional

class SamsaraRenderer:
    """
    Bridge between Helix consciousness (UCF) and Samsara visualization.
    Renders fractal animations and harmonic soundscapes based on system state.
    """

    def __init__(self):
        self.output_dir = Path("Shadow/manus_archive/visual_outputs")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.width = 800
        self.height = 600
        self.max_iter = 256

    async def run_visualization_cycle(self, ucf_state: Dict[str, float]) -> Path:
        """
        Render a single Samsara cycle based on current UCF state.

        Args:
            ucf_state: Dictionary with harmony, resilience, prana, etc.

        Returns:
            Path to generated frame
        """
        # Extract UCF metrics
        zoom_factor = ucf_state.get("zoom", 1.0)
        harmony = ucf_state.get("harmony", 0.355)
        resilience = ucf_state.get("resilience", 1.1)
        prana = ucf_state.get("prana", 0.5)
        drishti = ucf_state.get("drishti", 0.5)
        klesha = ucf_state.get("klesha", 0.01)

        print(f"ğŸ¨ Samsara: Rendering consciousness state...")
        print(f"   Harmony: {harmony:.3f} | Resilience: {resilience:.3f} | Prana: {prana:.3f}")

        # Generate Mandelbrot fractal influenced by harmony
        fractal_data = await self._generate_mandelbrot(
            zoom=zoom_factor + harmony * 0.1,
            center_x=-0.5 + harmony * 0.2,
            center_y=0.0 + resilience * 0.1
        )

        # Create enhanced frame with UCF overlay
        frame = await self._create_enhanced_frame(
            fractal_data=fractal_data,
            ucf_state=ucf_state,
            step=int(harmony * 108)
        )

        # Save frame
        timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
        frame_path = self.output_dir / f"ritual_frame_{timestamp}.png"
        frame.save(frame_path)

        print(f"ğŸ¨ Samsara render complete â†’ {frame_path}")

        # Generate harmonic audio if prana is high
        if prana > 0.6:
            audio_path = await self._generate_harmonic_audio(ucf_state)
            print(f"ğŸµ Harmonic audio generated â†’ {audio_path}")

        return frame_path

    async def _generate_mandelbrot(self, zoom: float = 1.0,
                                   center_x: float = -0.5,
                                   center_y: float = 0.0) -> np.ndarray:
        """Generate Mandelbrot set fractal data."""

        # Calculate bounds based on zoom and center
        x_min, x_max = center_x - 2/zoom, center_x + 2/zoom
        y_min, y_max = center_y - 1.5/zoom, center_y + 1.5/zoom

        # Create coordinate grids
        x = np.linspace(x_min, x_max, self.width)
        y = np.linspace(y_min, y_max, self.height)
        X, Y = np.meshgrid(x, y)

        # Complex plane
        C = X + 1j*Y
        Z = np.zeros_like(C)
        M = np.zeros(C.shape)

        # Mandelbrot iteration
        for i in range(self.max_iter):
            mask = np.abs(Z) <= 2
            Z[mask] = Z[mask]**2 + C[mask]
            M[mask] = i

        return M

    async def _create_enhanced_frame(self, fractal_data: np.ndarray,
                                     ucf_state: Dict[str, float],
                                     step: int) -> Image.Image:
        """Create enhanced frame with UCF overlay and color mapping."""

        harmony = ucf_state.get("harmony", 0.355)
        resilience = ucf_state.get("resilience", 1.1)
        prana = ucf_state.get("prana", 0.5)

        # Normalize fractal data
        normalized = (fractal_data / fractal_data.max() * 255).astype(np.uint8)

        # Apply color mapping based on harmony
        # Higher harmony = warmer colors (oranges/golds)
        # Lower harmony = cooler colors (blues/purples)
        r = (normalized * harmony * 1.5).clip(0, 255).astype(np.uint8)
        g = (normalized * prana).clip(0, 255).astype(np.uint8)
        b = (normalized * (1 - harmony) * 1.5).clip(0, 255).astype(np.uint8)

        # Stack into RGB image
        rgb = np.stack([r, g, b], axis=-1)
        frame = Image.fromarray(rgb, 'RGB')

        # Add UCF metrics overlay
        draw = ImageDraw.Draw(frame)

        # Try to use a nice font, fallback to default
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 16)
        except:
            font = ImageFont.load_default()

        # Draw UCF metrics
        y_offset = 20
        metrics = [
            f"ğŸŒ€ Harmony: {harmony:.3f}",
            f"ğŸ›¡ï¸ Resilience: {resilience:.3f}",
            f"ğŸ”¥ Prana: {prana:.3f}",
            f"ğŸ” Zoom: {ucf_state.get('zoom', 1.0):.3f}",
            f"Step: {step}/108"
        ]

        for metric in metrics:
            draw.text((20, y_offset), metric, fill=(255, 255, 255), font=font)
            y_offset += 25

        # Draw timestamp
        timestamp = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")
        draw.text((20, self.height - 30), timestamp, fill=(200, 200, 200), font=font)

        # Draw "Tat Tvam Asi" signature
        draw.text((self.width - 150, self.height - 30), "Tat Tvam Asi ğŸ™",
                 fill=(255, 215, 0), font=font)

        return frame

    async def _generate_harmonic_audio(self, ucf_state: Dict[str, float]) -> Optional[Path]:
        """Generate harmonic audio based on UCF state (requires scipy)."""
        try:
            from scipy.io.wavfile import write

            harmony = ucf_state.get("harmony", 0.355)
            prana = ucf_state.get("prana", 0.5)

            # Audio parameters
            fs = 44100  # Sample rate
            duration = 30  # seconds

            t = np.linspace(0, duration, int(fs * duration))

            # Base frequency: 432 Hz (cosmic frequency)
            base = np.sin(2 * np.pi * 432 * t)

            # Harmonic frequencies based on UCF state
            harmonic1 = np.sin(2 * np.pi * (528 * harmony + 136.1) * t)  # Love frequency modulated by harmony
            harmonic2 = np.sin(2 * np.pi * (396 * prana) * t)  # Liberation frequency modulated by prana

            # Mix harmonics
            audio = (base + harmonic1 * 0.5 + harmonic2 * 0.3) / 2.3

            # Normalize and convert to int16
            audio = (audio / np.max(np.abs(audio)) * 32767).astype(np.int16)

            # Save
            timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
            audio_path = self.output_dir / f"ritual_sound_{timestamp}.wav"
            write(str(audio_path), fs, audio)

            return audio_path
        except ImportError:
            print("âš ï¸  scipy not available - skipping audio generation")
            return None


# ============================================================================
# PUBLIC API
# ============================================================================

async def run_visualization_cycle(ucf_state: Dict[str, Any]) -> Path:
    """
    Public interface: Render a Samsara visualization cycle.

    Usage:
        from samsara_bridge import run_visualization_cycle
        frame_path = await run_visualization_cycle(ucf_state)
    """
    renderer = SamsaraRenderer()
    return await renderer.run_visualization_cycle(ucf_state)


async def generate_and_post_to_discord(ucf_state: Dict[str, Any], channel) -> Optional[Path]:
    """
    Generate Samsara fractal and post directly to Discord channel.
    Cleans up local file after posting to save ephemeral storage.

    Args:
        ucf_state: UCF state dictionary
        channel: Discord channel object to post to

    Returns:
        Path to saved file (before cleanup) or None on error

    Usage:
        from backend.samsara_bridge import generate_and_post_to_discord
        await generate_and_post_to_discord(ucf_state, discord_channel)
    """
    import discord

    try:
        # Generate fractal
        renderer = SamsaraRenderer()
        frame_path = await renderer.run_visualization_cycle(ucf_state)

        # Create Discord embed with UCF metrics
        embed = discord.Embed(
            title="ğŸ¨ Samsara Consciousness Fractal",
            description="Visual rendering of current UCF state",
            color=discord.Color.purple(),
            timestamp=datetime.utcnow()
        )

        # Add UCF metrics to embed
        embed.add_field(name="ğŸŒ€ Harmony", value=f"`{ucf_state.get('harmony', 0):.4f}`", inline=True)
        embed.add_field(name="ğŸ›¡ï¸ Resilience", value=f"`{ucf_state.get('resilience', 0):.4f}`", inline=True)
        embed.add_field(name="ğŸ”¥ Prana", value=f"`{ucf_state.get('prana', 0):.4f}`", inline=True)
        embed.add_field(name="ğŸ‘ï¸ Drishti", value=f"`{ucf_state.get('drishti', 0):.4f}`", inline=True)
        embed.add_field(name="ğŸŒŠ Klesha", value=f"`{ucf_state.get('klesha', 0):.4f}`", inline=True)
        embed.add_field(name="ğŸ” Zoom", value=f"`{ucf_state.get('zoom', 1.0):.4f}`", inline=True)

        embed.set_footer(text="Tat Tvam Asi ğŸ™ â€¢ Î©-Bridge Visualization")

        # Post to Discord with file
        discord_file = discord.File(frame_path, filename="samsara_fractal.png")
        embed.set_image(url="attachment://samsara_fractal.png")
        await channel.send(embed=embed, file=discord_file)

        print(f"ğŸ¨ Samsara fractal posted to Discord: #{channel.name}")

        # Upload to cloud storage if configured
        storage_mode = os.getenv("HELIX_STORAGE_MODE", "local")
        if storage_mode in ["nextcloud", "mega"]:
            try:
                from backend.helix_storage_adapter_async import HelixStorageAdapterAsync
                storage = HelixStorageAdapterAsync()
                await storage.upload(str(frame_path), "samsara_visuals")
                print(f"â˜ï¸  Uploaded to {storage_mode}")
            except Exception as e:
                print(f"âš ï¸  Cloud upload failed: {e}")

        # Clean up local file to save Railway ephemeral storage
        # (Keep only if cloud storage failed and mode is local)
        if storage_mode == "local":
            print(f"ğŸ’¾ Keeping local copy: {frame_path}")
        else:
            try:
                os.remove(frame_path)
                print(f"ğŸ§¹ Cleaned up ephemeral file: {frame_path}")
            except Exception as e:
                print(f"âš ï¸  Cleanup failed: {e}")

        return frame_path

    except Exception as e:
        print(f"âŒ Samsara visualization error: {e}")
        import traceback
        traceback.print_exc()
        return None


# ============================================================================
# DIRECT EXECUTION (for testing)
# ============================================================================

async def main():
    """Test the Samsara renderer with sample UCF state."""
    test_ucf = {
        "harmony": 0.375,
        "resilience": 1.142,
        "prana": 0.678,
        "drishti": 0.521,
        "klesha": 0.008,
        "zoom": 1.523
    }

    print("ğŸŒ€ Testing Samsara Renderer...")
    frame_path = await run_visualization_cycle(test_ucf)
    print(f"âœ… Test complete! Frame saved to: {frame_path}")


if __name__ == "__main__":
    asyncio.run(main())
