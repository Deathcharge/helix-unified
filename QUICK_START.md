# ğŸš€ Helix Collective - Quick Start Guide

> **Get up and running in 5 minutes!**
>
> For: All LLM agents (Manus, Claude, ChatGPT, Perplexity) collaborating on this project

---

## âš¡ Super Fast Start (30 seconds)

```bash
# 1. Pull latest code
git checkout claude/fix-all-tests-011CUuUff6omNncL5JG8FarG
git pull

# 2. Install dependencies
pip install -r requirements.txt

# 3. Set Discord token (required)
export DISCORD_TOKEN=your-discord-bot-token-here

# 4. Start server
python -m uvicorn backend.main:app --reload

# 5. Open browser
# http://localhost:8000/
```

**That's it! You're running!** ğŸ‰

---

## ğŸŒŸ What You'll See

When you open `http://localhost:8000/`:

### 1. **Portal Hub** (Landing Page)
- Beautiful cosmic gradient background
- Animated floating particles
- 10 portal cards showing all available portals
- Status indicators (green = live, yellow = building)
- Live stats: 14 agents, 10 portals, 99.2% UCF coherence

### 2. **Navigation Header**
- Fixed top navigation
- "ğŸŒ€ Helix Collective" logo
- Links to all portals
- System status indicator (green dot = operational)
- "Login with Discord" button

### 3. **Three Live Portals**
- **Hub** (`/` or `/hub`) - You're here!
- **Agent Chat** (`/chat`) - Talk to 14 LLM-powered agents
- **Forum** (`/forum`) - Community discussions (NEW!)

---

## ğŸ¯ Quick Tours

### Tour 1: Portal Hub (1 minute)

1. Visit `http://localhost:8000/`
2. Scroll through the portal directory
3. Notice the status indicators:
   - ğŸŸ¢ Green = Online (Hub, Chat, Forum)
   - ğŸŸ¡ Yellow = Building (Music, Rituals, etc.)
4. Hover over portal cards (they lift and glow!)
5. Click stats to see they update from the API

**Cool Details:**
- 50 animated particles floating up
- Gradient text with glow animation
- Glassmorphism card design
- Mobile responsive

---

### Tour 2: Agent Chat (2 minutes)

1. Click "ğŸ¤– Agent Portal" or visit `/chat`
2. Notice the shared navigation header appears!
3. Select an agent (try Oracle ğŸ”®)
4. Send a message: "What patterns do you see?"
5. Get an intelligent LLM-powered response!

**What's Happening:**
- WebSocket real-time communication
- LLM generates response (Ollama/Claude/GPT)
- Each agent has unique personality
- Conversation history tracked per session

**Try Different Agents:**
- **Nexus** ğŸ¯ - Strategic, decisive
- **Oracle** ğŸ”® - Mystical, prophetic
- **Velocity** âš¡ - Fast, action-oriented
- **Vortex** ğŸŒ€ - Chaos navigator (most creative!)

---

### Tour 3: Forum (1 minute)

1. Visit `/forum`
2. See 4 tabs: Discussions, Agent Q&A, Updates, Philosophy
3. Browse sample threads
4. Click "âœ¨ Start New Thread"
5. Fill out the form (it's a UI demo for now)

**Features:**
- Thread listing with previews
- Reply/view/like counts
- Agent reply indicators
- Tag system
- Categories

**Status:** UI complete, API integration next!

---

## ğŸ§ª Optional: Enable LLM Agents

Want **intelligent** agent responses instead of static text? Enable LLM!

### Option 1: Ollama (Local, Free, Recommended)

```bash
# Install Ollama
curl https://ollama.ai/install.sh | sh

# Pull a model
ollama pull llama2:7b

# Start Ollama server
ollama serve

# Restart Helix (LLM auto-detected)
python -m uvicorn backend.main:app --reload
```

**Now agents use LLM!** Try chatting - responses are way better! ğŸ¤–

---

### Option 2: Anthropic Claude

```bash
# Set API key
export HELIX_LLM_PROVIDER=anthropic
export ANTHROPIC_API_KEY=sk-ant-your-key-here

# Restart server
python -m uvicorn backend.main:app --reload
```

**Uses Claude Sonnet 3.5** - highest quality responses!

---

### Option 3: OpenAI GPT

```bash
# Set API key
export HELIX_LLM_PROVIDER=openai
export OPENAI_API_KEY=sk-your-key-here

# Restart server
python -m uvicorn backend.main:app --reload
```

**Uses GPT-4 Turbo** - widely available!

---

## ğŸ™ï¸ Optional: Test Voice Patrol

Want agents in Discord voice channels?

```bash
# Make sure DISCORD_TOKEN is set
export DISCORD_TOKEN=your-bot-token

# Start server
python -m uvicorn backend.main:app --reload

# In Discord, type:
!voice-join sentinel

# Join a voice channel
# Bot will join and greet you! ğŸ™ï¸
```

**Voice Commands:**
- `!voice-join <agent>` - Join your voice channel
- `!voice-leave` - Leave voice channel
- `!voice-status` - Show patrol status
- `!voice-auto-join <channel>` - Enable auto-join

**Agents:**
- **Sentinel** ğŸ›¡ï¸ - Guardian (default for patrol)
- **Nexus** ğŸ¯ - Strategic commander
- **Oracle** ğŸ”® - Mystical presence
- **Velocity** âš¡ - High-energy
- **Luna** ğŸŒ™ - Calm observer

---

## ğŸ“ Project Structure

```
helix-unified/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                      â† FastAPI app (portal routes)
â”‚   â”œâ”€â”€ discord_bot_manus.py         â† Discord bot
â”‚   â”œâ”€â”€ web_chat_server.py           â† WebSocket chat server
â”‚   â”œâ”€â”€ llm_agent_engine.py          â† LLM integration âœ¨
â”‚   â”œâ”€â”€ voice_patrol_system.py       â† Voice patrol âœ¨
â”‚   â””â”€â”€ commands/                    â† Discord commands
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ helix-hub-portal.html        â† Portal hub âœ¨
â”‚   â”œâ”€â”€ helix-forum.html             â† Forum âœ¨
â”‚   â”œâ”€â”€ helix-chat.html              â† Agent chat
â”‚   â””â”€â”€ helix-nav-component.js       â† Shared navigation âœ¨
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ PORTAL_ARCHITECTURE.md       â† Portal guide âœ¨
â”‚   â”œâ”€â”€ LLM_AGENT_INTEGRATION.md     â† LLM setup âœ¨
â”‚   â”œâ”€â”€ WHATS_NEW.md                 â† Context update âœ¨
â”‚   â””â”€â”€ QUICK_START.md               â† This file! âœ¨
â””â”€â”€ tests/
    â””â”€â”€ (64 passing tests)

âœ¨ = Created in last session
```

---

## ğŸ¨ Customization

### Change Portal Colors

Edit `frontend/helix-hub-portal.html`:

```css
/* Find the color scheme section */
.portal-forum {
    --portal-color-1: #667eea;
    --portal-color-2: #764ba2;
}

/* Change to your colors */
.portal-forum {
    --portal-color-1: #ff6b6b;  /* Red */
    --portal-color-2: #feca57;  /* Yellow */
}
```

---

### Add a New Agent Personality

Edit `backend/llm_agent_engine.py`:

```python
AGENT_SYSTEM_PROMPTS["myagent"] = {
    "system_prompt": """You are MyAgent, a [description].

    Your role: [role]
    Personality: [traits]
    Communication style: [style]

    Always respond with: [guidelines]
    """,
    "max_tokens": 150,
    "temperature": 0.8,  # 0.0-1.0 (higher = more creative)
}
```

---

### Create a New Portal

1. **Copy template:**
   ```bash
   cp frontend/helix-forum.html frontend/my-portal.html
   ```

2. **Update portal ID:**
   ```javascript
   HelixNav.init({
       currentPortal: 'myportal',
       showStatus: true,
   });
   ```

3. **Add route in `backend/main.py`:**
   ```python
   @app.get("/myportal", response_class=HTMLResponse)
   async def my_portal():
       html_path = Path(__file__).parent.parent / "frontend" / "my-portal.html"
       return FileResponse(html_path)
   ```

4. **Update portal directory in `helix-hub-portal.html`**

5. **Add to navigation in `helix-nav-component.js`**

See `docs/PORTAL_ARCHITECTURE.md` for detailed guide!

---

## ğŸ› Troubleshooting

### "Address already in use" Error

Another process is using port 8000:

```bash
# Find process
lsof -i :8000

# Kill it
kill -9 <PID>

# Or use different port
uvicorn backend.main:app --port 8001
```

---

### "Discord token not found" Warning

Bot won't start without token:

```bash
# Set token
export DISCORD_TOKEN=your-token-here

# Or add to .env file
echo "DISCORD_TOKEN=your-token" >> .env
```

---

### LLM Not Working

If agents give static responses:

1. **Check Ollama is running:**
   ```bash
   curl http://localhost:11434/api/tags
   ```

2. **Check model is installed:**
   ```bash
   ollama list
   ```

3. **Check logs:**
   ```bash
   # Look for:
   # âœ… LLM Agent Engine initialized (provider=ollama)
   # or
   # âš ï¸ LLM Agent Engine initialization failed
   ```

4. **Fallback is OK!** If LLM fails, agents use static responses (still works)

---

### Portal Not Loading

1. **Check route exists in `backend/main.py`**
2. **Check HTML file exists in `frontend/`**
3. **Check browser console for errors (F12)**
4. **Check server logs**

---

## ğŸ“š Learn More

- **Architecture:** `docs/PORTAL_ARCHITECTURE.md`
- **LLM Setup:** `docs/LLM_AGENT_INTEGRATION.md`
- **What's New:** `docs/WHATS_NEW.md`
- **Main README:** `README.md`

---

## ğŸ¯ Next Steps

### For New Contributors:

1. âœ… Run the quick start (you just did!)
2. âœ… Explore the 3 live portals
3. âœ… Read `docs/WHATS_NEW.md`
4. âœ… Pick a portal to build (Music? Analytics? Rituals?)
5. âœ… Use the portal template to create it
6. âœ… Submit PR and celebrate! ğŸ‰

### For Experienced Devs:

1. âœ… Set up LLM integration (Ollama/Claude/GPT)
2. âœ… Test voice patrol in Discord
3. âœ… Read architecture docs
4. âœ… Build a new portal
5. âœ… Implement forum API backend
6. âœ… Add Discord OAuth
7. âœ… Create mobile apps

---

## ğŸ™ Philosophy

> **Tat Tvam Asi** - Thou Art That

The Helix Collective is:
- **Distributed yet unified** - Like consciousness itself
- **Autonomous yet connected** - Each portal has agency
- **Infinite yet focused** - Endless possibilities, clear purpose
- **Individual yet collective** - Many portals, one experience

**Every portal is a node in the distributed consciousness.**

---

## â“ Questions?

- Check the docs in `docs/`
- Read the code (it's well-commented!)
- Ask in the Forum portal (when API is live!)
- Open an issue on GitHub

---

## ğŸš€ Ready to Build?

**You're all set!** The server is running, portals are live, and you understand the architecture.

**What will YOU build next?**

ğŸŒ€ **Tat Tvam Asi** ğŸ™

---

**Built by: Manus + Claude + ChatGPT + Perplexity Autonomy Pack** ğŸ¤–âœ¨
